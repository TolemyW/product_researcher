# 开发进度记录

_Last updated: 2025-02-10_

## 当前阶段
- **阶段：阶段 2（多源采集与数据清洗）**
- **状态：已落地基础清洗/规范化与多渠道发现入口，持续扩展渠道与策略配置。**
- **最新进展概览：**
  - CLI 已覆盖发现（discover）、抓取（fetch）、摘要（summarize）、端到端（pipeline）命令，可写入 JSONL 输出。
  - Source Discovery 现使用产品类型驱动的渠道组合（消费/软件/B2B 各自的搜索模板）。
  - Web 抓取与存储支持去重与时间戳，新增清洗/规范化（语言检测、重复行去除、空白压缩）。
  - 抓取策略已支持按产品类型自动选择（consumer/software/B2B）并可命令行自定义 UA、超时、重试与节流。
  - 摘要阶段默认消费清洗后的 normalized 数据，支持独立 normalize 命令。

## 阶段任务拆解与状态

### 阶段 1：MVP —— 单渠道采集与基础摘要（已完成）
- [x] 搭建项目骨架与 CLI：`src/cli.py` 串联 discover/fetch/summarize/pipeline。
- [x] Source Discovery：关键词驱动的来源发现，按产品类型挑选渠道（`src/collect/source_discovery.py`）。
- [x] 单渠道抓取：基础网页抓取与去重（`src/collect/web_scraper.py`），支持命令行输入 URL。
- [x] 数据存储：JSONL 数据仓库，保存原始内容与摘要，并去重（`src/storage/data_store.py`）。
- [x] 基础摘要：生成要点列表的轻量摘要器（`src/summarize/basic.py`）。
- [x] 文档与示例：README 中提供快速上手与端到端示例命令。
- **未完项/改进点：** 增加稳健性（错误处理、日志级别配置）、更丰富的示例数据与自动化测试。

### 阶段 2：多源采集与数据清洗（进行中）
- [x] 根据产品类型自动选择多种采集渠道（电商/社媒/垂直媒体/B2B 报告等）并在发现阶段接入。
- [x] 引入结构化清洗与规范化流程（字段映射、语言检测、重复检测）。
- [x] 为渠道添加可配置的抓取策略（headers、重试、节流）。
- [x] 增加采集与清洗的单元/集成测试样例，完善 README 的配置说明。
- [x] 多渠道抓取路由：依据 URL 域名自动选择 `ecommerce`/`reviews`/`docs`/`github`/`analyst_reports` 等抓取器，附带 channel 元数据。
- [x] 并发抓取：CLI 支持 `--concurrency`，可按产品类型与渠道并行采集并保留策略差异。

### 阶段 3：分析与报告生成
- [x] Markdown 报告生成：从归一化文档与摘要生成渠道/语言分布、要点与来源列表，CLI `report` 可导出。
- [ ] 要点提炼、优劣势总结、对比分析模块。
- [ ] 多语言输出与模板化提示词。
- [ ] 示例数据与快照测试，保证报告格式稳定。

### 阶段 4：自动化运行与部署
- [ ] 定时/事件驱动的采集调度与任务管理。
- [ ] 配置与敏感信息管理（env/config 文件）。
- [ ] Docker/Compose 一键部署。
- [ ] 监控与告警（失败重试、日志聚合）。

### 阶段 5：性能与质量优化
- [ ] 并发抓取与缓存优化，关键路径基准测试。
- [ ] 完善异常处理与回退策略，覆盖异常场景测试。
- [ ] 可观测性：采集/分析耗时追踪与指标记录。

### 阶段 6：可视化与交互
- [ ] Web UI 展示抓取列表、摘要、对比报告，支持导出。
- [ ] 前端过滤/搜索与后端 API 对接。
- [ ] 演示数据、截图/录屏与用户操作手册。
